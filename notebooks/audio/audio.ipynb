{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv('/home/saashiv/Code/EMR/data/audio_data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "emergency_classes = ['dog_bark', 'car_horn', 'gun_shot','siren','jackhammer','drilling']  # Add more classes as needed\n",
    "filtered_metadata = metadata[metadata['class'].isin(emergency_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(index_row):\n",
    "    index, row = index_row\n",
    "    if index%100==0:\n",
    "        print(f\"Processing index: {index}, class: {row['class']}\")\n",
    "    file_path = f'/home/saashiv/Code/EMR/data/audio_data/UrbanSound8K/audio/fold{row[\"fold\"]}/{row[\"slice_file_name\"]}'\n",
    "    class_label = row['classID']  # or row['class'] if you want the string label\n",
    "    \n",
    "    # Load audio file\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    return mfccs,class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4732\n",
      "Processing index: 0, class: dog_bark\n",
      "Processing index: 100, class: drilling\n",
      "Processing index: 200, class: jackhammer\n",
      "Processing index: 300, class: siren\n",
      "Processing index: 400, class: dog_bark\n",
      "Processing index: 500, class: siren\n",
      "Processing index: 600, class: jackhammer\n",
      "Processing index: 700, class: jackhammer\n",
      "Processing index: 800, class: gun_shot\n",
      "Processing index: 900, class: drilling\n",
      "Processing index: 1000, class: siren\n",
      "Processing index: 1100, class: drilling\n",
      "Processing index: 1200, class: siren\n",
      "Processing index: 1300, class: gun_shot\n",
      "Processing index: 1400, class: siren\n",
      "Processing index: 1500, class: drilling\n",
      "Processing index: 1600, class: gun_shot\n",
      "Processing index: 1700, class: drilling\n",
      "Processing index: 1800, class: jackhammer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saashiv/miniconda3/envs/ERP/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index: 1900, class: dog_bark\n",
      "Processing index: 2000, class: jackhammer\n",
      "Processing index: 2100, class: dog_bark\n",
      "Processing index: 2200, class: drilling\n",
      "Processing index: 2300, class: jackhammer\n",
      "Processing index: 2400, class: car_horn\n",
      "Processing index: 2500, class: jackhammer\n",
      "Processing index: 2600, class: dog_bark\n",
      "Processing index: 2700, class: jackhammer\n",
      "Processing index: 2800, class: dog_bark\n",
      "Processing index: 2900, class: jackhammer\n",
      "Processing index: 3000, class: siren\n",
      "Processing index: 3100, class: dog_bark\n",
      "Processing index: 3200, class: jackhammer\n",
      "Processing index: 3300, class: drilling\n",
      "Processing index: 3400, class: siren\n",
      "Processing index: 3500, class: drilling\n",
      "Processing index: 3600, class: dog_bark\n",
      "Processing index: 3700, class: drilling\n",
      "Processing index: 3800, class: jackhammer\n",
      "Processing index: 3900, class: siren\n",
      "Processing index: 4000, class: drilling\n",
      "Processing index: 4100, class: car_horn\n",
      "Processing index: 4200, class: jackhammer\n",
      "Processing index: 4300, class: siren\n",
      "Processing index: 4400, class: drilling\n",
      "Processing index: 4500, class: drilling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saashiv/miniconda3/envs/ERP/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "/home/saashiv/miniconda3/envs/ERP/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "/home/saashiv/miniconda3/envs/ERP/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "/home/saashiv/miniconda3/envs/ERP/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index: 4600, class: siren\n",
      "Processing index: 4700, class: drilling\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata = None\n",
    "filtered_metadata = None\n",
    "metadata = pd.read_csv('/home/saashiv/Code/EMR/data/audio_data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "emergency_classes = ['dog_bark', 'car_horn', 'gun_shot','siren','jackhammer','drilling']  # Add more classes as needed\n",
    "filtered_metadata = metadata[metadata['class'].isin(emergency_classes)]\n",
    "filtered_metadata.reset_index(drop=True, inplace=True)\n",
    "print(len(filtered_metadata))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    results = list(executor.map(feature_extraction, filtered_metadata.iterrows()))\n",
    "    \n",
    "for mfccs, class_label in results:\n",
    "    X.append(mfccs)\n",
    "    y.append(class_label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9165786694825766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume X is your feature matrix and y is your label vector\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice_file_name    137815-4-0-7.wav\n",
      "fsID                         137815\n",
      "start                      3.706472\n",
      "end                        7.706472\n",
      "salience                          1\n",
      "fold                              9\n",
      "classID                           4\n",
      "class                      drilling\n",
      "Name: 851, dtype: object\n"
     ]
    }
   ],
   "source": [
    "random_row = filtered_metadata.sample(1).iloc[0]\n",
    "print(random_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: [4] actual label: drilling\n"
     ]
    }
   ],
   "source": [
    "file_path = f'/home/saashiv/Code/EMR/data/audio_data/UrbanSound8K/audio/fold{random_row[\"fold\"]}/{random_row[\"slice_file_name\"]}'\n",
    "audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "mfccs = mfccs.reshape(1, -1)  # Reshape to match the expected input shape for the classifier\n",
    "predicted_label = clf.predict(mfccs)\n",
    "print(\"Predicted Label:\", predicted_label, 'actual label:',random_row['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/saashiv/Code/EMR/ML models/audio_model/ML_audio_model.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(clf, '/home/saashiv/Code/EMR/ML models/audio_model/ML_audio_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('random_forest_audio_model.joblib')\n",
    "\n",
    "# To use the loaded model to make predictions\n",
    "# predictions = loaded_model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
